{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4일차 5교시 집계 연산\n",
    "\n",
    "### 목차\n",
    "* 1. 집계 함수 예제\n",
    "* 2. Group By 예제\n",
    "* 3. SparkContext vs. SparkSession\n",
    "\n",
    "### 참고 사이트\n",
    "* [PySpark Search](https://spark.apache.org/docs/latest/api/python/search.html)\n",
    "* [Pyspark Functions](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?#module-pyspark.sql.functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"Asia/Seoul\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 구매 이력 데이터 \"\"\"\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"data/retail-data/all\") \\\n",
    "    .coalesce(5)\n",
    "df.cache()\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate   |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |12/1/2010 8:26|2.55     |17850     |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |12/1/2010 8:26|2.75     |17850     |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(5, truncate=False)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 집계 함수\n",
    "### 1.1 로우 수 (count, countDistinct, approx_count_distinct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  541909|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1454|\n",
      "+--------+\n",
      "\n",
      "+------------------+\n",
      "|count(Description)|\n",
      "+------------------+\n",
      "|            540455|\n",
      "+------------------+\n",
      "\n",
      "+-------------------------+\n",
      "|count(DISTINCT StockCode)|\n",
      "+-------------------------+\n",
      "|                     4070|\n",
      "+-------------------------+\n",
      "\n",
      "+-------------------------+\n",
      "|count(DISTINCT StockCode)|\n",
      "+-------------------------+\n",
      "|                     4070|\n",
      "+-------------------------+\n",
      "\n",
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|                            3364|\n",
      "+--------------------------------+\n",
      "\n",
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|                            4079|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.printSchema()\n",
    "df.selectExpr(\"count(*)\").show()\n",
    "df.where(\"Description is null\").selectExpr(\"count(1)\").show() # 1,454\n",
    "df.selectExpr(\"count(Description)\").show() # 540,455 + 1,454 = 541,909\n",
    "\n",
    "# 명시적으로 컬럼을 지정한 경우 해당 컬럼이 널 인 경우 해당 로우는 제외됩니다\n",
    "df.select(countDistinct(\"StockCode\")).show()\n",
    "df.selectExpr(\"count(distinct StockCode)\").show()\n",
    "\n",
    "# 근사치로 구하지만 연산 속도가 빠름\n",
    "df.select(approx_count_distinct(\"StockCode\", 0.1)).show() # 0.1은 최대 추정 오류율\n",
    "df.select(approx_count_distinct(\"StockCode\", 0.01)).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 수치 집계 함수 (first, last, min, max, sum, sumDistinct, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+\n",
      "|first(StockCode, false)|last(StockCode, false)|\n",
      "+-----------------------+----------------------+\n",
      "|                 85123A|                 22138|\n",
      "+-----------------------+----------------------+\n",
      "\n",
      "+-------------+-------------+\n",
      "|min(Quantity)|max(Quantity)|\n",
      "+-------------+-------------+\n",
      "|       -80995|        80995|\n",
      "+-------------+-------------+\n",
      "\n",
      "+--------------------+-----------------+\n",
      "|    min(Description)| max(Description)|\n",
      "+--------------------+-----------------+\n",
      "| 4 PURPLE FLOCK D...|wrongly sold sets|\n",
      "+--------------------+-----------------+\n",
      "\n",
      "+-------------+\n",
      "|sum(Quantity)|\n",
      "+-------------+\n",
      "|      5176450|\n",
      "+-------------+\n",
      "\n",
      "+----------------------+\n",
      "|sum(DISTINCT Quantity)|\n",
      "+----------------------+\n",
      "|                 29310|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.select(first(\"StockCode\"), last(\"StockCode\")).show(1) # null도 감안하려면 True\n",
    "\n",
    "df.select(min(\"Quantity\"), max(\"Quantity\")).show(1)\n",
    "df.select(min(\"Description\"), max(\"Description\")).show(1) # 문자열\n",
    "\n",
    "df.select(sum(\"Quantity\")).show(1)\n",
    "df.select(sumDistinct(\"Quantity\")).show(1) # 고유값을 합산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 통계 집계 함수 (avg, mean, variance, stddev) \n",
    "* 표본표준분산 및 편차: variance, stddev\n",
    "* 모표준분산 및 편차 : var_pop, stddev_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+----------------+-----------------+\n",
      "|(total_purchases / total_transcations)|   avg_purchases|mean_transcations|\n",
      "+--------------------------------------+----------------+-----------------+\n",
      "|                      9.55224954743324|9.55224954743324| 9.55224954743324|\n",
      "+--------------------------------------+----------------+-----------------+\n",
      "\n",
      "+------------------+---------------------+------------------+---------------------+------------------+--------------------+\n",
      "|var_samp(Quantity)|stddev_samp(Quantity)|var_samp(Quantity)|stddev_samp(Quantity)| var_pop(Quantity)|stddev_pop(Quantity)|\n",
      "+------------------+---------------------+------------------+---------------------+------------------+--------------------+\n",
      "|47559.391409298696|   218.08115785023404|47559.391409298696|   218.08115785023404|47559.303646609005|  218.08095663447784|\n",
      "+------------------+---------------------+------------------+---------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df.select(\n",
    "    count(\"Quantity\").alias(\"total_transcations\"),\n",
    "    sum(\"Quantity\").alias(\"total_purchases\"),\n",
    "    avg(\"Quantity\").alias(\"avg_purchases\"),\n",
    "    expr(\"mean(Quantity)\").alias(\"mean_transcations\"),    \n",
    ").selectExpr(\n",
    "    \"total_purchases / total_transcations\",\n",
    "    \"avg_purchases\",\n",
    "    \"mean_transcations\").show(3)\n",
    "\n",
    "df.select(variance(\"Quantity\"), stddev(\"Quantity\"),      \n",
    "          var_samp(\"Quantity\"), stddev_samp(\"Quantity\"),\n",
    "          var_pop(\"Quantity\"), stddev_pop(\"Quantity\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 그룹핑 (Group By)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 표현식을 이용한 그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+---------+----------+---------------+\n",
      "|InvoiceNo|CustomerId|CountOfQuantity|\n",
      "+---------+----------+---------------+\n",
      "|   536846|     14573|             76|\n",
      "|   537026|     12395|             12|\n",
      "|   537883|     14437|              5|\n",
      "|   538068|     17978|             12|\n",
      "|   538279|     14952|              7|\n",
      "+---------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "df.printSchema()\n",
    "df.groupBy(\"InvoiceNo\", \"CustomerId\").agg(expr(\"count(Quantity) as CountOfQuantity\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 맵을 이용한 그룹화\n",
    "> 파이선의 딕셔너리 데이터 타입을 활용하여 집계함수의 표현이 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+------------------+\n",
      "|InvoiceNo|stddev_pop(UnitPrice)|     avg(Quantity)|\n",
      "+---------+---------------------+------------------+\n",
      "|   536596|    6.618375094302897|               1.5|\n",
      "|   536938|   2.4313249096586267|33.142857142857146|\n",
      "|   537252|                  0.0|              31.0|\n",
      "|   537691|    2.761232695735729|              8.15|\n",
      "|   538041|                  0.0|              30.0|\n",
      "+---------+---------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"InvoiceNo\").agg( { \"Quantity\" : \"avg\", \"UnitPrice\" : \"stddev_pop\" } ).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습#9 data/tbl_purchase.csv 데이터를 읽고, 최소, 최대 구매금액을 구하세요\n",
    "> selectExpr, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|min(p_amount)|max(p_amount)|\n",
      "+-------------+-------------+\n",
      "|      1000000|      4500000|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchase = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"data/tbl_purchase.csv\")\n",
    "purchase.selectExpr(\"min(p_amount)\", \"max(p_amount)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습#10 data/tbl_purchase.csv 데이터를 읽고, 유저별(p_uid) 전체 구매금액(p_amount)을 출력하세요\n",
    "> groupBy, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|p_uid|sum(p_amount)|\n",
      "+-----+-------------+\n",
      "|    1|      3800000|\n",
      "|    3|      1000000|\n",
      "|    5|      6000000|\n",
      "|    4|      4500000|\n",
      "|    2|      1400000|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"data/tbl_user.csv\")\n",
    "\n",
    "purchase.groupBy(\"p_uid\").sum(\"p_amount\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
